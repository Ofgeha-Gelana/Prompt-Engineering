{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ofge/Documents/icog/Prompt-Engineering/pe/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "model = genai.GenerativeModel('gemini-1.5-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine a regular computer bit like a light switch, either on (1) or off (0).  A quantum bit, or qubit, is like a dimmer switch. It can be on, off, or a mixture of both at the same time. This \"both at once\" state is called superposition.\n",
      "\n",
      "Another key idea is entanglement.  Imagine two of our dimmer switches linked together magically.  If you change one, the other instantly changes too, no matter how far apart they are.  Entangled qubits are like this, their fates intertwined.\n",
      "\n",
      "Because qubits can be in multiple states at once, and because they can be linked through entanglement, a quantum computer can explore many possibilities simultaneously.  This allows it to tackle certain types of problems, like drug discovery or materials science, much faster than regular computers.\n",
      "\n",
      "It's important to remember that quantum computers are not meant to replace regular computers.  They're good at different things. Think of them as specialized tools for specific, complex problems, not for browsing the internet or writing emails.  They're still in early stages of development, but have the potential to revolutionize certain fields.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define your prompt\n",
    "prompt = \"Explain quantum computing in simple terms. (e.g., no *, **, or other formatting symbols).\"\n",
    "\n",
    "# Generate a response\n",
    "response = model.generate_content(prompt)\n",
    "\n",
    "# Print the response\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamental Prompting Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Instructional Prompts\n",
    "#### Description: Instructional prompts are used to provide step-by-step instructions for completing a task. They are useful for guiding the model to generate detailed and structured outputs.\n",
    "##### *Use Case*: Provide step-by-step instructions to bake a chocolate cake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhausted",
     "evalue": "429 Resource has been exhausted (e.g. check quota).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mResourceExhausted\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      2\u001b[39m prompt = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33mProvide step-by-step instructions to bake a chocolate cake.\u001b[39m\n\u001b[32m      4\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[33m(e.g., no *, **, or other formatting symbols)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Generate response\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m response = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mInstructional Prompts Output:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/icog/Prompt-Engineering/pe/lib/python3.12/site-packages/google/generativeai/generative_models.py:331\u001b[39m, in \u001b[36mGenerativeModel.generate_content\u001b[39m\u001b[34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[39m\n\u001b[32m    329\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types.GenerateContentResponse.from_iterator(iterator)\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m         response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    335\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types.GenerateContentResponse.from_response(response)\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m google.api_core.exceptions.InvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/icog/Prompt-Engineering/pe/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:835\u001b[39m, in \u001b[36mGenerativeServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    834\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m835\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    843\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/icog/Prompt-Engineering/pe/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/icog/Prompt-Engineering/pe/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:293\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    289\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    290\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    291\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    292\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/icog/Prompt-Engineering/pe/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:153\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m    150\u001b[39m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    152\u001b[39m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[32m    164\u001b[39m     time.sleep(sleep)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/icog/Prompt-Engineering/pe/lib/python3.12/site-packages/google/api_core/retry/retry_base.py:212\u001b[39m, in \u001b[36m_retry_error_helper\u001b[39m\u001b[34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[32m    207\u001b[39m     final_exc, source_exc = exc_factory_fn(\n\u001b[32m    208\u001b[39m         error_list,\n\u001b[32m    209\u001b[39m         RetryFailureReason.NON_RETRYABLE_ERROR,\n\u001b[32m    210\u001b[39m         original_timeout,\n\u001b[32m    211\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msource_exc\u001b[39;00m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    214\u001b[39m     on_error_fn(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/icog/Prompt-Engineering/pe/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:144\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    146\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/icog/Prompt-Engineering/pe/lib/python3.12/site-packages/google/api_core/timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m         remaining_timeout = \u001b[38;5;28mself\u001b[39m._timeout\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/icog/Prompt-Engineering/pe/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:78\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(*args, **kwargs)\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mResourceExhausted\u001b[39m: 429 Resource has been exhausted (e.g. check quota)."
     ]
    }
   ],
   "source": [
    "# Instructional prompt\n",
    "prompt = \"\"\"\n",
    "Provide step-by-step instructions to bake a chocolate cake.\n",
    "\n",
    "1. Preheat the oven to 350°F (175°C).\n",
    "2. Grease and flour a cake pan.\n",
    "3. Mix flour, sugar, cocoa powder, baking powder, and salt in a bowl.\n",
    "4. Add eggs, milk, oil, and vanilla extract. Mix until smooth.\n",
    "5. Pour the batter into the prepared pan.\n",
    "6. Bake for 30-35 minutes or until a toothpick inserted into the center comes out clean.\n",
    "7. Let the cake cool before serving.\n",
    "(e.g., no *, **, or other formatting symbols)\n",
    "\"\"\"\n",
    "\n",
    "# Generate response\n",
    "response = model.generate_content(prompt)\n",
    "print(\"Instructional Prompts Output:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The output** provides a clear, step-by-step guide to baking a chocolate cake. Each step is logically ordered, ensuring that even a beginner can follow the instructions. This demonstrates how instructional prompts can generate structured and actionable outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Role Prompting\n",
    "\n",
    "**Description**: Role prompting involves asking the model to act as a specific role (e.g., a teacher, doctor, or chef). This helps tailor the response to the context of the role.\n",
    "\n",
    "##### *Use Case*: Ask the model to act as a history teacher and explain the causes of World War I."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Role prompting\n",
    "prompt = \"\"\"\n",
    "You are a history teacher. Explain the causes of World War I in simple terms.\n",
    "\n",
    "World War I was caused by a combination of factors, including militarism, alliances, imperialism, and nationalism. The assassination of Archduke Franz Ferdinand of Austria-Hungary in 1914 was the immediate trigger.\n",
    "(e.g., no *, **, or other formatting symbols)\n",
    "\"\"\"\n",
    "\n",
    "# Generate response\n",
    "response = model.generate_content(prompt)\n",
    "print(\"Role Prompting Output:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The output** explains the causes of World War I in simple terms, as if a history teacher were addressing students. It highlights key factors like militarism, alliances, imperialism, and nationalism, and mentions the assassination of Archduke Franz Ferdinand as the immediate trigger. This demonstrates how role prompting can generate context-specific and educational responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Text Classification\n",
    "\n",
    "#### Description: Text classification involves categorizing text into predefined labels or categories. It is useful for organizing and analyzing large amounts of text data.\n",
    "\n",
    "#### *Use Case*: Classify a text into one of the categories: Sports, Politics, Technology, or Entertainment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text classification prompt\n",
    "prompt = \"\"\"\n",
    "Classify the following text into one of the categories: Sports, Politics, Technology, Entertainment.\n",
    "\n",
    "Text: \"The new smartphone features a 108MP camera and 5G connectivity.\"\n",
    "Category: Technology \n",
    "\"\"\"\n",
    "\n",
    "# Generate response\n",
    "response = model.generate_content(prompt)\n",
    "print(\"Text Classification Output:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The output** correctly classifies the text as \"Technology\" because it discusses features of a smartphone, such as a 108MP camera and 5G connectivity. This demonstrates how text classification can be used to automatically categorize text based on its content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Code Generation\n",
    "#### Description: Code generation involves asking the model to write code to solve a specific problem. This is useful for automating programming tasks or generating boilerplate code.\n",
    "#### *Use Case*: Generate Python code to check if a number is prime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code generation prompt\n",
    "prompt = \"\"\"\n",
    "Write a Python function to check if a number is prime.\n",
    "\n",
    "Code:\n",
    "```python\n",
    "def is_prime(n):\n",
    "    if n <= 1:\n",
    "        return False\n",
    "    for i in range(2, int(n**0.5) + 1):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *The output* is a Python function that checks if a number is prime. It uses a common algorithm that tests divisibility up to the square root of the number. This demonstrates how code generation can automate the creation of functional and efficient code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Reasoning\n",
    "\n",
    "#### Description: Reasoning prompts are used to solve problems that require logical thinking or step-by-step analysis. They help the model break down complex problems into manageable steps.\n",
    "\n",
    "#### Use Case: Solve a reasoning problem step-by-step (e.g., calculate the average speed of a train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reasoning prompt\n",
    "prompt = \"\"\"\n",
    "Solve the following problem step by step:\n",
    "\n",
    "Problem: If a train travels 300 miles in 5 hours, what is its average speed?\n",
    "\n",
    "Step 1: Calculate the total distance traveled (300 miles).\n",
    "Step 2: Calculate the total time taken (5 hours).\n",
    "Step 3: Divide the distance by the time to get the average speed.\n",
    "Average speed = 300 miles / 5 hours = 60 miles per hour. (e.g., no *, **, or other formatting symbols)\n",
    "\"\"\"\n",
    "\n",
    "# Generate response\n",
    "response = model.generate_content(prompt)\n",
    "print(\"Reasoning Output:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Few-Shot Learning\n",
    "#### Use Case: Customer Support Email Classification\n",
    "\n",
    "Classify customer support emails into categories like \"Billing,\" \"Technical Support,\" \"Account Issues,\" or \"General Inquiry.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-shot learning prompt\n",
    "prompt = \"\"\"\n",
    "Classify the following customer support emails into one of the categories: Billing, Technical Support, Account Issues, General Inquiry.\n",
    "\n",
    "Example 1:  \n",
    "Email: \"I can't log in to my account. It says my password is incorrect.\"  \n",
    "Category: Account Issues  \n",
    "\n",
    "Example 2:  \n",
    "Email: \"I was charged twice for my subscription this month. Can you refund the extra charge?\"  \n",
    "Category: Billing  \n",
    "\n",
    "Example 3:  \n",
    "Email: \"The app keeps crashing when I try to open it on my phone.\"  \n",
    "Category: Technical Support  \n",
    "\n",
    "Now classify this email:  \n",
    "Email: \"I want to know more about your premium subscription plans.\"  \n",
    "Category:\n",
    "\"\"\"\n",
    "\n",
    "response = model.generate_content(prompt)\n",
    "print(\"Output for Few-Shot Learning:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The model uses the provided examples to classify the new email. Since the email asks about subscription plans, it falls under the General Inquiry category. The output demonstrates how few-shot learning helps the model generalize from examples to new inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Chain-of-Thought (CoT) Prompting\n",
    "\n",
    "#### **Use Case**: Solving Math Word Problems\n",
    "Solve a multi-step math problem by breaking it down into logical steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CoT prompt\n",
    "prompt = \"\"\"\n",
    "Solve the following problem step by step:  \n",
    "\n",
    "Problem: A bakery sells 120 cupcakes in a day. If each cupcake costs $2.50 and the bakery operates 6 days a week, how much revenue does the bakery generate in a week?  \n",
    "\n",
    "Step 1: Calculate daily revenue.  \n",
    "Daily revenue = Number of cupcakes per day × Cost per cupcake  \n",
    "Daily revenue = 120 × $2.50 = $300  \n",
    "\n",
    "Step 2: Calculate weekly revenue.  \n",
    "Weekly revenue = Daily revenue × Number of operating days per week  \n",
    "Weekly revenue = $300 × 6 = $1800  \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Generate response\n",
    "response = model.generate_content(prompt)\n",
    "print(\"Output for Chain-of-Thought Prompting:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The model** follows the step-by-step reasoning provided in the prompt to solve the problem. It first calculates the daily revenue and then scales it up to weekly revenue. The output demonstrates how CoT helps the model handle complex, multi-step problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Self-Consistency\n",
    "\n",
    "#### Use Case: Fact Verification\n",
    "Verify the accuracy of a statement by cross-checking it with multiple reasoning paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-consistency prompt\n",
    "prompt = \"\"\"\n",
    "Verify the following statement by providing two different reasoning paths:  \n",
    "\n",
    "Statement: \"The Eiffel Tower is located in London.\"  \n",
    "\n",
    "Reasoning Path 1:  \n",
    "The Eiffel Tower is a famous landmark in Paris, France. London is the capital of the United Kingdom. Therefore, the statement is false.  \n",
    "\n",
    "Reasoning Path 2:  \n",
    "The Eiffel Tower was built for the 1889 World's Fair in Paris. It has never been relocated to London. Thus, the statement is false.  \n",
    "\n",
    "Conclusion: Both reasoning paths confirm that the statement is false.  \n",
    "\"\"\"\n",
    "\n",
    "# Generate response\n",
    "response = model.generate_content(prompt)\n",
    "print(\"Output for Self-Consistency:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The model** provides two distinct reasoning paths to verify the statement. Both paths conclude that the Eiffel Tower is not in London, demonstrating how self-consistency ensures reliable and accurate results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Generate Knowledge Prompting\n",
    "\n",
    "#### Use Case: Explaining Complex Concepts\n",
    "Explain a complex concept like \"quantum computing\" in simple terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate knowledge prompt\n",
    "prompt = \"\"\"\n",
    "Explain quantum computing in simple terms by generating relevant knowledge points:  ((e.g., no *, **, or other formatting symbols).  \n",
    ")\n",
    "\n",
    "1. Quantum computing uses qubits instead of classical bits.  \n",
    "2. Qubits can exist in multiple states at once (superposition).  \n",
    "3. Quantum computers leverage entanglement to perform complex calculations faster.  \n",
    "4. They are useful for solving problems like cryptography, optimization, and drug discovery.  \n",
    "\n",
    "Explanation: Quantum computing is a new type of computing that uses qubits, which can be in multiple states at the same time. This allows quantum computers to solve certain problems much faster than traditional computers, especially in fields like cryptography and scientific research.  \n",
    "\"\"\"\n",
    "\n",
    "# Generate response\n",
    "response = model.generate_content(prompt)\n",
    "print(\"Output for Generate Knowledge Prompting:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The model** generates a concise explanation of quantum computing, breaking it down into key points. The output demonstrates how generate knowledge prompting helps the model provide clear and informative explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Program-aided Language Model (PAL)\n",
    "\n",
    "#### Use Case: Writing Code to Solve a Problem\n",
    "Generate Python code to calculate the factorial of a number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### PAL prompt\n",
    "prompt = \"\"\"\n",
    "Write a Python function to calculate the factorial of a given number using recursion.  \n",
    "\n",
    "Code:  \n",
    "```python\n",
    "def factorial(n):  \n",
    "    if n == 0 or n == 1:  \n",
    "        return 1  \n",
    "    else:  \n",
    "        return n * factorial(n - 1)  \n",
    "\n",
    "# Example usage:  \n",
    "print(factorial(5))  # Output: 120  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Description of Output:**  \n",
    "The model generates a Python function to calculate the factorial of a number using recursion. The output demonstrates how PAL enables the model to write functional code for specific tasks.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary of Outputs\n",
    "| **Technique**               | **Output Description**                                                                 |\n",
    "|-----------------------------|---------------------------------------------------------------------------------------|\n",
    "| Few-Shot Learning           | Classifies a new email as \"General Inquiry\" based on provided examples.               |\n",
    "| Chain-of-Thought (CoT)      | Solves a math problem step-by-step, calculating weekly revenue for a bakery.          |\n",
    "| Self-Consistency            | Verifies a false statement using two distinct reasoning paths.                        |\n",
    "| Generate Knowledge Prompting| Explains quantum computing in simple terms with key points.                           |\n",
    "| Program-aided Language Model| Generates Python code to calculate the factorial of a number using recursion.         |\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
