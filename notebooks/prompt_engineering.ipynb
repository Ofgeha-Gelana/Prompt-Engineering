{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Problem Statement\n",
    "The rapid advancement of Large Language Models (LLMs) has opened up new possibilities for solving complex real-world problems. However, effectively leveraging these models requires the ability to design and craft prompts that guide the model to generate accurate, relevant, and useful outputs. This project aims to explore and demonstrate the application of **Fundamental** and **Advanced Prompting Techniques** using the **Gemini API** to solve a variety of tasks.:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objectives:**\n",
    "- To demonstrate the effectiveness of **Fundamental Prompting Techniques** in solving basic tasks such as instruction generation, role-based responses, text classification, code generation, and reasoning.\n",
    "- To explore **Advanced Prompting Techniques** such as Few-Shot Learning, Chain-of-Thought (CoT) Prompting, Self-Consistency, Generate Knowledge Prompting, and Program-aided Language Models (PAL) for solving more complex and nuanced problems.\n",
    "- To provide a comprehensive set of examples and use cases that showcase the practical applications of these techniques in real-world scenarios.\n",
    "- To highlight the importance of **Prompt Engineering** as a critical skill for effectively utilizing Large Language Models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ofge/Documents/icog/Prompt-Engineering/pe/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "model = genai.GenerativeModel('gemini-1.5-pro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamental Prompting Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Instructional Prompts\n",
    "#### Description: Instructional prompts are used to provide step-by-step instructions for completing a task. They are useful for guiding the model to generate detailed and structured outputs.\n",
    "##### *Use Case*: Provide step-by-step instructions to bake a chocolate cake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instructional Prompts Output:\n",
      "1. Preheat oven to 350°F (175°C).\n",
      "2. Grease and flour a 9x13 inch cake pan.  Alternatively, grease and flour two 9-inch round cake pans.\n",
      "3. In a large bowl, whisk together 2 cups all-purpose flour, 2 cups granulated sugar, ¾ cup unsweetened cocoa powder, 1 ½ teaspoons baking powder, 1 ½ teaspoons baking soda, and 1 teaspoon salt.\n",
      "4. Add 2 large eggs, 1 cup milk, ½ cup vegetable oil, 2 teaspoons vanilla extract, and 1 cup boiling water to the dry ingredients.\n",
      "5. Beat with an electric mixer on medium speed for 2 minutes.  The batter will be thin.\n",
      "6. Pour batter into the prepared pan(s).\n",
      "7. Bake for 30-35 minutes for a 9x13 inch pan, or 25-30 minutes for two 9-inch round pans, or until a wooden skewer inserted into the center comes out clean.\n",
      "8. Let the cake cool in the pan for 10 minutes before inverting it onto a wire rack to cool completely.\n",
      "9. Frost and decorate as desired once the cake is completely cool. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instructional prompt\n",
    "prompt = \"\"\"\n",
    "Provide step-by-step instructions to bake a chocolate cake.\n",
    "\n",
    "1. Preheat the oven to 350°F (175°C).\n",
    "2. Grease and flour a cake pan.\n",
    "3. Mix flour, sugar, cocoa powder, baking powder, and salt in a bowl.\n",
    "4. Add eggs, milk, oil, and vanilla extract. Mix until smooth.\n",
    "5. Pour the batter into the prepared pan.\n",
    "6. Bake for 30-35 minutes or until a toothpick inserted into the center comes out clean.\n",
    "7. Let the cake cool before serving.\n",
    "(e.g., no *, **, or other formatting symbols)\n",
    "\"\"\"\n",
    "\n",
    "# Generate response\n",
    "response = model.generate_content(prompt)\n",
    "print(\"Instructional Prompts Output:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The output** provides a clear, step-by-step guide to baking a chocolate cake. Each step is logically ordered, ensuring that even a beginner can follow the instructions. This demonstrates how instructional prompts can generate structured and actionable outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Role Prompting\n",
    "\n",
    "**Description**: Role prompting involves asking the model to act as a specific role (e.g., a teacher, doctor, or chef). This helps tailor the response to the context of the role.\n",
    "\n",
    "##### *Use Case*: Ask the model to act as a history teacher and explain the causes of World War I."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role Prompting Output:\n",
      "Alright class, imagine Europe in 1914 as a bunch of kids in a playground, all pushing and shoving each other.  Nobody *wants* a big fight, but everyone is tense and ready for one.  Why?\n",
      "\n",
      "First, **militarism**: everyone was building up their armies and navies, showing off their new weapons, and bragging about how tough they were.  This made everyone nervous and suspicious.\n",
      "\n",
      "Second, **alliances**: imagine cliques on the playground.  Countries had promised to defend each other if attacked.  So if one kid started a fight, their whole group would jump in. Austria-Hungary and Germany were friends, as were France, Russia and Great Britain.\n",
      "\n",
      "Third, **imperialism**:  these \"kids\" were also fighting over toys – colonies in Africa and Asia.  They wanted the resources and the prestige of controlling these areas. This created rivalry and resentment.\n",
      "\n",
      "Fourth, **nationalism**:  each country thought they were the best and felt a strong sense of pride and loyalty.  This sometimes turned into a belief that they were superior to other countries and deserved more power.  Think of it like extreme school spirit, where you think your school is the *only* good one.\n",
      "\n",
      "Finally, the spark that started the whole fight: the assassination of Archduke Franz Ferdinand, heir to the throne of Austria-Hungary.  Think of it like one kid finally snapping and shoving another.  Because of the alliances, that small shove quickly turned into a huge brawl – World War I.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Role prompting\n",
    "prompt = \"\"\"\n",
    "You are a history teacher. Explain the causes of World War I in simple terms.\n",
    "\n",
    "World War I was caused by a combination of factors, including militarism, alliances, imperialism, and nationalism. The assassination of Archduke Franz Ferdinand of Austria-Hungary in 1914 was the immediate trigger.\n",
    "(e.g., no *, **, or other formatting symbols)\n",
    "\"\"\"\n",
    "\n",
    "# Generate response\n",
    "response = model.generate_content(prompt)\n",
    "print(\"Role Prompting Output:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The output** explains the causes of World War I in simple terms, as if a history teacher were addressing students. It highlights key factors like militarism, alliances, imperialism, and nationalism, and mentions the assassination of Archduke Franz Ferdinand as the immediate trigger. This demonstrates how role prompting can generate context-specific and educational responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Text Classification\n",
    "\n",
    "#### Description: Text classification involves categorizing text into predefined labels or categories. It is useful for organizing and analyzing large amounts of text data.\n",
    "\n",
    "#### *Use Case*: Classify a text into one of the categories: Sports, Politics, Technology, or Entertainment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Classification Output:\n",
      "Your classification is correct.  The text clearly describes features of a smartphone, which falls under the **Technology** category.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Text classification prompt\n",
    "prompt = \"\"\"\n",
    "Classify the following text into one of the categories: Sports, Politics, Technology, Entertainment.\n",
    "\n",
    "Text: \"The new smartphone features a 108MP camera and 5G connectivity.\"\n",
    "Category: Technology \n",
    "\"\"\"\n",
    "\n",
    "# Generate response\n",
    "response = model.generate_content(prompt)\n",
    "print(\"Text Classification Output:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The output** correctly classifies the text as \"Technology\" because it discusses features of a smartphone, such as a 108MP camera and 5G connectivity. This demonstrates how text classification can be used to automatically categorize text based on its content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Code Generation\n",
    "#### Description: Code generation involves asking the model to write code to solve a specific problem. This is useful for automating programming tasks or generating boilerplate code.\n",
    "#### *Use Case*: Generate Python code to check if a number is prime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code generation prompt\n",
    "prompt = \"\"\"\n",
    "Write a Python function to check if a number is prime.\n",
    "\n",
    "Code:\n",
    "```python\n",
    "def is_prime(n):\n",
    "    if n <= 1:\n",
    "        return False\n",
    "    for i in range(2, int(n**0.5) + 1):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *The output* is a Python function that checks if a number is prime. It uses a common algorithm that tests divisibility up to the square root of the number. This demonstrates how code generation can automate the creation of functional and efficient code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Reasoning\n",
    "\n",
    "#### Description: Reasoning prompts are used to solve problems that require logical thinking or step-by-step analysis. They help the model break down complex problems into manageable steps.\n",
    "\n",
    "#### Use Case: Solve a reasoning problem step-by-step (e.g., calculate the average speed of a train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reasoning Output:\n",
      "Step 1: The total distance traveled is given as 300 miles.\n",
      "\n",
      "Step 2: The total time taken is given as 5 hours.\n",
      "\n",
      "Step 3:  Divide the total distance by the total time to find the average speed.\n",
      "\n",
      "Average speed = 300 miles / 5 hours = 60 miles per hour.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reasoning prompt\n",
    "prompt = \"\"\"\n",
    "Solve the following problem step by step:\n",
    "\n",
    "Problem: If a train travels 300 miles in 5 hours, what is its average speed?\n",
    "\n",
    "Step 1: Calculate the total distance traveled (300 miles).\n",
    "Step 2: Calculate the total time taken (5 hours).\n",
    "Step 3: Divide the distance by the time to get the average speed.\n",
    "Average speed = 300 miles / 5 hours = 60 miles per hour. (e.g., no *, **, or other formatting symbols)\n",
    "\"\"\"\n",
    "\n",
    "# Generate response\n",
    "response = model.generate_content(prompt)\n",
    "print(\"Reasoning Output:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Few-Shot Learning\n",
    "#### Use Case: Customer Support Email Classification\n",
    "\n",
    "Classify customer support emails into categories like \"Billing,\" \"Technical Support,\" \"Account Issues,\" or \"General Inquiry.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output for Few-Shot Learning:\n",
      "General Inquiry\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Few-shot learning prompt\n",
    "prompt = \"\"\"\n",
    "Classify the following customer support emails into one of the categories: Billing, Technical Support, Account Issues, General Inquiry.\n",
    "\n",
    "Example 1:  \n",
    "Email: \"I can't log in to my account. It says my password is incorrect.\"  \n",
    "Category: Account Issues  \n",
    "\n",
    "Example 2:  \n",
    "Email: \"I was charged twice for my subscription this month. Can you refund the extra charge?\"  \n",
    "Category: Billing  \n",
    "\n",
    "Example 3:  \n",
    "Email: \"The app keeps crashing when I try to open it on my phone.\"  \n",
    "Category: Technical Support  \n",
    "\n",
    "Now classify this email:  \n",
    "Email: \"I want to know more about your premium subscription plans.\"  \n",
    "Category:\n",
    "\"\"\"\n",
    "\n",
    "response = model.generate_content(prompt)\n",
    "print(\"Output for Few-Shot Learning:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The model uses the provided examples to classify the new email. Since the email asks about subscription plans, it falls under the General Inquiry category. The output demonstrates how few-shot learning helps the model generalize from examples to new inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Chain-of-Thought (CoT) Prompting\n",
    "\n",
    "#### **Use Case**: Solving Math Word Problems\n",
    "Solve a multi-step math problem by breaking it down into logical steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output for Chain-of-Thought Prompting:\n",
      "Your solution is perfectly correct and clearly explained!\n",
      "\n",
      "The bakery generates $1800 in revenue per week.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CoT prompt\n",
    "prompt = \"\"\"\n",
    "Solve the following problem step by step:  \n",
    "\n",
    "Problem: A bakery sells 120 cupcakes in a day. If each cupcake costs $2.50 and the bakery operates 6 days a week, how much revenue does the bakery generate in a week?  \n",
    "\n",
    "Step 1: Calculate daily revenue.  \n",
    "Daily revenue = Number of cupcakes per day × Cost per cupcake  \n",
    "Daily revenue = 120 × $2.50 = $300  \n",
    "\n",
    "Step 2: Calculate weekly revenue.  \n",
    "Weekly revenue = Daily revenue × Number of operating days per week  \n",
    "Weekly revenue = $300 × 6 = $1800  \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Generate response\n",
    "response = model.generate_content(prompt)\n",
    "print(\"Output for Chain-of-Thought Prompting:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The model** follows the step-by-step reasoning provided in the prompt to solve the problem. It first calculates the daily revenue and then scales it up to weekly revenue. The output demonstrates how CoT helps the model handle complex, multi-step problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Self-Consistency\n",
    "\n",
    "#### Use Case: Fact Verification\n",
    "Verify the accuracy of a statement by cross-checking it with multiple reasoning paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output for Self-Consistency:\n",
      "Your reasoning and conclusion are correct. The statement \"The Eiffel Tower is located in London\" is demonstrably false, and you've provided two valid and distinct lines of reasoning to show why.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Self-consistency prompt\n",
    "prompt = \"\"\"\n",
    "Verify the following statement by providing two different reasoning paths:  \n",
    "\n",
    "Statement: \"The Eiffel Tower is located in London.\"  \n",
    "\n",
    "Reasoning Path 1:  \n",
    "The Eiffel Tower is a famous landmark in Paris, France. London is the capital of the United Kingdom. Therefore, the statement is false.  \n",
    "\n",
    "Reasoning Path 2:  \n",
    "The Eiffel Tower was built for the 1889 World's Fair in Paris. It has never been relocated to London. Thus, the statement is false.  \n",
    "\n",
    "Conclusion: Both reasoning paths confirm that the statement is false.  \n",
    "\"\"\"\n",
    "\n",
    "# Generate response\n",
    "response = model.generate_content(prompt)\n",
    "print(\"Output for Self-Consistency:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The model** provides two distinct reasoning paths to verify the statement. Both paths conclude that the Eiffel Tower is not in London, demonstrating how self-consistency ensures reliable and accurate results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Generate Knowledge Prompting\n",
    "\n",
    "#### Use Case: Explaining Complex Concepts\n",
    "Explain a complex concept like \"quantum computing\" in simple terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output for Generate Knowledge Prompting:\n",
      "1. Quantum computers use quantum mechanics.\n",
      "2. Classical computers store information as bits (0 or 1).\n",
      "3. Qubits can be 0, 1, or both simultaneously (superposition).\n",
      "4. Superposition allows quantum computers to explore many possibilities at once.\n",
      "5. Entanglement links two or more qubits together.  \n",
      "6. Entangled qubits influence each other instantaneously, even when separated.\n",
      "7. Quantum algorithms exploit superposition and entanglement.\n",
      "8. Quantum computers aren't meant to replace classical computers.\n",
      "9. They excel at specific tasks classical computers struggle with.\n",
      "10.  Quantum computing is still in its early stages of development.\n",
      "11. Building and maintaining quantum computers is challenging.\n",
      "\n",
      "\n",
      "Explanation:  Quantum computers harness the strange rules of quantum mechanics to solve complex problems.  Unlike classical computers that use bits which are either 0 or 1, quantum computers use qubits. Qubits can be both 0 and 1 at the same time through a concept called superposition.  Another key idea is entanglement, where qubits become linked and affect each other even when far apart.  These properties allow quantum computers to explore many possibilities simultaneously, making them potentially much faster for certain tasks like drug discovery and breaking encryption. However, this technology is still developing and faces significant technical hurdles.  They won't replace our everyday computers, but rather work alongside them for specialized applications. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate knowledge prompt\n",
    "prompt = \"\"\"\n",
    "Explain quantum computing in simple terms by generating relevant knowledge points:  ((e.g., no *, **, or other formatting symbols).  \n",
    ")\n",
    "\n",
    "1. Quantum computing uses qubits instead of classical bits.  \n",
    "2. Qubits can exist in multiple states at once (superposition).  \n",
    "3. Quantum computers leverage entanglement to perform complex calculations faster.  \n",
    "4. They are useful for solving problems like cryptography, optimization, and drug discovery.  \n",
    "\n",
    "Explanation: Quantum computing is a new type of computing that uses qubits, which can be in multiple states at the same time. This allows quantum computers to solve certain problems much faster than traditional computers, especially in fields like cryptography and scientific research.  \n",
    "\"\"\"\n",
    "\n",
    "# Generate response\n",
    "response = model.generate_content(prompt)\n",
    "print(\"Output for Generate Knowledge Prompting:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The model** generates a concise explanation of quantum computing, breaking it down into key points. The output demonstrates how generate knowledge prompting helps the model provide clear and informative explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Program-aided Language Model (PAL)\n",
    "\n",
    "#### Use Case: Writing Code to Solve a Problem\n",
    "Generate Python code to calculate the factorial of a number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### PAL prompt\n",
    "prompt = \"\"\"\n",
    "Write a Python function to calculate the factorial of a given number using recursion.  \n",
    "\n",
    "Code:  \n",
    "```python\n",
    "def factorial(n):  \n",
    "    if n == 0 or n == 1:  \n",
    "        return 1  \n",
    "    else:  \n",
    "        return n * factorial(n - 1)  \n",
    "\n",
    "# Example usage:  \n",
    "print(factorial(5))  # Output: 120  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Description of Output:**  \n",
    "The model generates a Python function to calculate the factorial of a number using recursion. The output demonstrates how PAL enables the model to write functional code for specific tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary of Outputs\n",
    "| **Technique**                     | **Output Description**                                                                 |\n",
    "|-----------------------------------|---------------------------------------------------------------------------------------|\n",
    "| **Fundamental Techniques**        |                                                                                       |\n",
    "| Instructional Prompts             | Provides step-by-step instructions for baking a chocolate cake.                       |\n",
    "| Role Prompting                    | Explains the causes of World War I as a history teacher.                              |\n",
    "| Text Classification               | Classifies a text about a smartphone as \"Technology.\"                                 |\n",
    "| Code Generation                   | Generates a Python function to check if a number is prime.                            |\n",
    "| Reasoning                         | Calculates the average speed of a train (60 miles per hour).                          |\n",
    "| **Advanced Techniques**           |                                                                                       |\n",
    "| Few-Shot Learning                 | Classifies a new email as \"General Inquiry\" based on provided examples.               |\n",
    "| Chain-of-Thought (CoT) Prompting  | Solves a math problem step-by-step, calculating weekly revenue for a bakery.          |\n",
    "| Self-Consistency                  | Verifies a false statement using two distinct reasoning paths.                        |\n",
    "| Generate Knowledge Prompting      | Explains quantum computing in simple terms with key points.                           |\n",
    "| Program-aided Language Models (PAL)| Generates Python code to calculate the factorial of a number using recursion.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
